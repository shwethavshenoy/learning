Kubernetes

Docker: platform for creating immutable images. run containers.
Cons: Good for small systems. Not Enterprise scale.


Kubernetes: Containers + orchestration through service discovery
from Google project: Borg - minimal version of Borg.
It is one of the projects hosted on CNCF. like etcd

Equivalents to K8S: Docker Swarm, Mesoshphere
Kubernetes Master : K8S config service: takes in the configuration / workload definition (yaml/json) via API / UI / kubectl
talks to workers / nodes via kublets running on them.
nodes will pull the images from dockerhub or private docker registry


Minikube: Small one node cluster with k8s 1.3

K8s Multi-node Cluster: prod env

Managed K8S: Openshift dedicated, Google Kubernetes Engine(GKE), Azure Container Engine (AKS), IBM Cloud Container Service.

Google container engine - Google compute engine - K8S can be installed with a few commands. - a turnkey solution (IaaS) like Azure

Tools to install K8s: Kubeadm (first class citizens in K8s), Kubespray - an incubator project in K8S, kops. Only kops allows provisioning of the vms as well.

Google container engine - Google compute engine - K8S can be installed with a few commands. - a turnkey solution (IaaS) like Azure
-----------------------------------------------------
Terminology:
node: host or a vm
container: unit of packaging
pod: unit of deployment: homogenous containers. vms that bring up multiple containers and make them available as one. Containers that need to be together can be created as a pod.
contains one processid, network namespace (*namespaces support multiple virtual clusters backed by a physical cluster)
Replication Controller: ensures desired state of scalability and availability. ex: 3 pods always running
Labels: kv pairs. The keys that define the services and objects running in kubernetes containers
Services: collection of pods exposed as an endpoint
-----------------------------------------------------

Kubernetes Master components: 
API Server exposes a set of APIs for operations available. All administration requests get to API server.
Scheduler: schedules pods across nodes that meets a particular criteria. 
Controller manager: Co-ordination & health of cluster.
etcd - lightweight, distributed key-value db. Stores cluster state. Can also be deployed separetly and then connected to master.

kubectl - CLI that consumes APIs from API Server. - Go lang based
Kubernetes dashboard also uses the same API Server. All requests pass through this

Kubernetes Master talks to nodes. 
k8S master doesn't host any pods. 
-----------------------------------------------------
K8S Nodes / slave /Minions
Main components:

Contain kubeproxy - maintains network config. Manipulates ip tables on each host for pod to pod, node to node comm.

kubelet - agent that talks to API (master). reports health and state

Container Runtime - to run and maintain container's runtime

kubelet talks to the container runtime using container runtime Interface (CRI). It consists of protobuf, gRPC (Client and server APIs).  
The CRI shim (gRPC server) implements 2 services: ImageService (for image related ops) and runtime service (for container and pod related ops)

Examples of CRI shims: dockershim, cri-containerdshim, CRI-O (for Open Container Initiative compatible runtimes)

docker - platform that creates containers. runtime - containerd

kubelet + docker = supervisord

fluentd - log management for central logging

Addons: DNS management, UI - help dev

Kubernetes implements Container Network Interface (CNI) to assign each pod a unique IP address. (IP assignment offloading happens at the CNI, which then forwards the request to one of the underlying configured plugins like Bridge, IPvlan to get the IP. Then it forwards it back to the requested container runtime.

Containers within in the same pod share the network namespace.

For inter pod communication (hosted on different nodes), there should be no Network addresss Translation. This can be achieved by GKE or using software that defines networking like Flannel, Weave, Calico etc. Softwares also allows for setting of Network policies.

-----------------------------------------------------
Starting minikube:

open cmd prompt, navigate to the location which contains minikube exe.
-----------------------------------------------------
minikube start --vm-driver=virtualbox

--container-runtime=cri-o is also another option to use a different CRI. (CRIs include: dockershim, cri-containerdshim and cri-o)

this starts a small kubernetes orchestrated cluster. IT also creates a config file inside the .kube directory inside user's home. Thi file contains the connectivity details to the api server on master node.

These are visible in virtualbox

Also configures kubectl (client) to minikube

NOTE:if --vm-driver=none is used, it uses the host not vm. However, a network bridge needs to be setup for docker. If not, upon restart, there will loss of connectivity to the cluster.
-----------------------------------------------------

minikube status

prints running / stopped status of the container
-----------------------------------------------------
minikube dashboard

pulls up a dashboard showing info on the cluster
-----------------------------------------------------
point docker cli to minikube:
Execute the following:
1. minikube docker-env

This outputs a bunch of variables.
Execute the last line: Since the delimiters have a problem in windows 10, add delims=ctrl+L to the command.
@FOR /f "tokens=* delims=^L" %i IN ('minikube docker-env') DO %i

Then execute docker commands on terminal
-----------------------------------------------------
Terminology:
node: host

container: unit of packaging

pod: unit of deployment: homogenous containers. vms that bring up multiple containers and make them available as one. Containers that need to be together can be created as a pod.

Replication Controller: ensures desired state of scalability and availability. ex: 3 pods always running

Labels: kv pairs. The keys that define the services and objects running in kubernetes containers

Services: collection of pods exposed as an endpoint

etcd - distributed kv pair db
-----------------------------------------------------

Communication with the k8s cluster can be done via: CLI, API and GUI.
-----------------------------------------------------
kubectl config view
displays the config from the .kube directory in user's home by default. It also displays other clusters that it connected to and the current context.
-----------------------------------------------------
kubectl version
prints client and server versions of K8S
-----------------------------------------------------
kubectl cluster-info (dump)
prints out the info on the master and nodes
dump: option presents a verbose output of all the config.
-----------------------------------------------------
kubectl get nodes
prints details on the running node
-----------------------------------------------------
kubectl get cs (component status)
prints status of different components
-----------------------------------------------------
kubectl config use-context <name>
switches the context to the different setup
-----------------------------------------------------
kubectl run my-web --image=nginx --port=80
Creates a deployment with name my-web

similar to docker run command
-----------------------------------------------------
kubectl get deployments

prints the deployment data: desired number of pods, current number, available ones etc.
-----------------------------------------------------
kubectl get pods
options:
 --show-labels
prints the details of the pods
--show-labels will display the labels that are associated with it.
pod-template-hash is generated by k8s to keep track of the updated deployments
 --selector env=production,dev-lead!=ssh
 prints info only on those pods which have a label that matches the selector.
 -l 'release-version (not)in (1.0,2.0)
 prints info on all those pods that have label of release-version with values between 1.0 and 2.0 (both ends inclusive)
 (not)in - as one word

Other examples:
kubectl get pods -o wide
prints pod info with info like what pod is running on which node

-----------------------------------------------------
kubectl expose deployment my-web --target-port=80 --type=NodePort
creates a service that is accessible on port 80 internally

types:
ClusterIP: service is available only internally with in the pod
NodePort: exposes the service at Node's IP. ClusterIP service is auto created. NodePort will route to the ClusterIP service internally. Meant for outside contact.
LoadBalancer: exposes the service on the cloud provider's LB. NodePort and ClusterIP services are auto created.
More: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services---service-types
-----------------------------------------------------
kubectl get svc / kubectl get services
prints the services with name, ip, port (Internal:external) along with protocol
-----------------------------------------------------
minikube ip
displays the ip of the k8s server
-----------------------------------------------------
kubectl describe svc <name>
prints the info on the service like the clusterIP, namespace, labels, publish type, endpoints etc.
-----------------------------------------------------
kubectl proxy
starts to serve a webapp on a url upon hitting which a list of APIs are returned.
-----------------------------------------------------
heapster - container essential for kubernetes master. Scheduling is disabled on K8S master node as itdoesnt host containers.
-----------------------------------------------------
Service is bound to the pod definition -- selector definition in service should match the  labels in pod definition.
----------------------------------------------------
kubectl create -f <yaml file with pod def>
creates a pod for that definiton
-----------------------------------------------------
kubectl delete pod <pod_name>
deletes the pod
----------------------------------------------------
kubectl delete svc <service_name>
deletes the service with this name
----------------------------------------------------
kubectl exec -it <pod> /bin/bash
to execute commands on the running container. Similar to docker exec.
----------------------------------------------------
Any of the nodes could be hosting the application. kube proxy will route them to the appropriate node properly. To know which nodes actually running the application execute kubectl describe pod
--------------------------------------------------- 
kubectl describe pod <name>
describes the pod of given name
---------------------------------------------------
REplication Controller -- number of pods
kubectl get rc

prints the data on Replication controller. Number desired, current number of pods age etc.
---------------------------------------------------
kubectl scale rc web replicas=10
scale the pods as desired outside of the cofig from ReplicationController definition

**useful when some pods need to be scaled temporarily
---------------------------------------------------
kubectl expose pod <name> --type=NodePort
exposes the said pod to the outside world. Creates a service in the background.

Another way would be to define a service.
---------------------------------------------------
kubectl describe svc / pod/ node <name> 
describes the said object.
---------------------------------------------------
Replication Controllers use labels and selectors to associate RC with pods
Replica sets are next gen RCs, they use Annotations and querying to associate with pods.
Can make the query very granular

---------------------------------------------------
Kubernetes Volume Types

Host based volumes: 
a. EmptyDir: temp, created when pod is scheduled. Ephemeral.
b. HostPath: Exposes on of the existent dirs to K8s. persistent.

Block Storage-based volumes:
like disks created on GCE. These disks are persistent and the data is not deleted even when the pod is deleted. However, they are not distributed, multiple pods cant access it at the same time.

Prod: storageClass recommended 

PersistentVolume (PV): network storage created by admin, governed by a quota.

PersistentVolumeClaim (PVC): Claims made on the PV by users. PV quota could be 5G. Claim could be for 1G.

StorageClass: drivers/interfaces. supported storage profiles offered by admins. example: nfs. 
Mentioned in the PersistentVolume object definition.

Claim needn't know the StorageClass. Only needs to know the max available capacity.


StatefulSets / Pecsets - stateful, persistent

---------------------------------------------------
Deployments:
Defines the state of application with config like: number of replicas, versions needed etc.
Create, update, perform rolling updates, rollback, pause/resume a deployment

kubectl create -f <file> --record
creates a deployment

kubectl get deployments
prints the deployments

kubectl set image deployment/<name> <image>:<image:newVersion>
updates the image to be deployed

where is this data on new version stored as the file has a different version. etcd?

kubectl rollout status deployment/<name>
prints status of roll out
---------------------------------------------------
kubectl edit deployment/<name>
opens an editable window for the deployment

the changes reflect immediately
---------------------------------------------------
kubectl rollout undo deployment/<name>
rollback of previous updates 
---------------------------------------------------
Exact external port can be deinfed by nodePort property in the service.
---------------------------------------------------
watch kubectl get pods
will print the information and watches them for changes
---------------------------------------------------
kubectl rollout history deployment <name>
prints out the revisions of the deployment
---------------------------------------------------
kubectl delete deployment <name>
Deletes deployments
---------------------------------------------------
kubectl delete svc <name>
deletes the service
---------------------------------------------------
kubectl rollout pause <deployment>
pauses deployment
---------------------------------------------------
kubectl rollout resume <deployment>
resumes deployment
---------------------------------------------------
kubectl apply svc -f  yaml.yml
applies the changes to the existing service
---------------------------------------------------

The DNS of services are automatically resolve namespaces in the same cluster.

If services are from other cluster, use headless service, a router to point to the external service
---------------------------------------------------
kubernetes service loadbalancer = loadbalancer + proxy
---------------------------------------------------
kubectl cordon <node IP>
detaches the node from live cluster  / disables further scheduling of pods on this node
doesnt remove the existing pods
---------------------------------------------------
kubectl drain <node>
disables scheduling + moves the pods from the node gracefully

kubectl drain <node> --force
will forcefully evict all pods from this node

nodes that are not a part of replica set / rc will not be moved to a different node
---------------------------------------------------
kubectl uncordon <node IP>
brings back the node to scheduling

nodes that were drained /cordoned can be bought back this way
---------------------------------------------------
kubectl delete -f <yml file>
works just like kubectl delete pod/rc/svc <name>
---------------------------------------------------
kubectl get pods --watch-only
fetches any changes that were made to the pods
---------------------------------------------------
kubectl port-forward <pod> <ContainerPort>:<anotherPort>
Without a service, the pod can be accessed on localhost via the another port. This pod is not exposed to the outside world.
---------------------------------------------------
kubectl exec -it <podName> /bin/should
drops the user into the pod
---------------------------------------------------
kubectl cp ./test.html <pod>:<mountpath>/test.html
to copy files from localhost into the pod without mounting the volume

kubectl cp <pod>:<mountpath>/<file> ./test.html
copy files from the pod onto localdisc
---------------------------------------------------
kubectl explain 
prints all short forms available for accessing objects.
pod - pod
services - svc
persistentvolumes - pv
persistentvolumeclaims - pvc
deployments deploy
---------------------------------------------------
kubectl get pod <name> -o=yaml/json
prints the data in the output format provided.
Makes it easier to reverse engineer a running pod into another service template.
---------------------------------------------------
kubectl get pods web -o jsonpath={.spec.containers[*].name}
prints the container names. jsonpath is an expression that is evaluated and data matching that is printed.
---------------------------------------------------
kubectl get services --sort-by=.metadata.name
sorting of services by a particular criteria
---------------------------------------------------
KUBE_EDITOR="sublime" kubectl edit pod/<name>
opens the yaml of the pod in the mentioned editor for editing.
default is vim (linux/Mac)
---------------------------------------------------
kubectl proxy

options --port=8000: if you want access on a partucular port
opens a tunnel into k8s cluster
---------------------------------------------------
Objects can be created by CURL command as well by hitting the API server directly instead of kubectl (that also internally makes calls to the API server)
---------------------------------------------------

ConfigMaps - K8S Objects for injecting containers with config data. Holds KV pairs. container agnostic. Can also hold config files itself
First class citizens. No dynamic changes allowed. Any change to configmap needs a redeploy of the pod

Populates values of env-variables/config files in a volume, set cmd-line args in a container

env -variable setting: Referred to in other objects by a configMapKeyRef section in the spec/Containers/env/valuefrom

configMaps can also be created from files: kubectl create configmap example-redis-config --from-file=redis-config
can also be created from literal values:  kubectl create configmap logger --from-literal=log_level=debug
log_level is the key and debug is its value
This can be referred to in the deployment as configMapKeyRef
name - name of the configMap
key - key from which the value needs lookup

---------------------------------------------------
Secrets: store senstive data like passwords, tokens,keys, size limited, access restricted to only the pod that requires it (stored in tempfs), registerd with k8s master, communication between k8s API server and node is through SSL/TLS, 

Can also be created via a yaml file

kubectl create secret generic dbsecret --from-file=./username.txt --from-file=./password.txt ....
creates secret named "dbsecret"

stores the data in Base64 encoded text. Not encrypted

Can also be injected as env variables inject under: secretKeyRef 

They can also be created from literals with --from-literal=<key>=<value>

API server stores secrets in plain text
When etcd cluster is replicated, secrets are sent in plain text

---------------------------------------------------

Ingress - Logical controller since k8s 1.2

external urls - decouples the nodeport from the url. So, external url will remain same inspite of underlying url change

makes wiring nodePorts to LBs easier.
external LBs can be easily configured.
SSL termination

 special deamon thread listens for requests at /ingress on the API server to track changes to the ingress



---------------------------------------------------
K8S also provides structs for health check probes in deployment
readiness probe: to detect when the pod can start accepting requests
liveliness probe: to ensure container is healthy

So, the deployment / Pod is unavailable / not ready till the readiness check has passed.

When the pod is describe it would be marked unhealthy if it is not available.

---------------------------------------------------
minikube service <name>
Opens up the service in browser
---------------------------------------------------
kubectl get all
displays all the objects currently running. Pods, services, deployments etc.
-------------------------------------
minikube addons list
displays the list of addons that are instaled with their status enabled/disabled
dashboard is a addon
-------------------------------------
minikube addons enable heapster
enables the addon, heapster in minikube
heapster runs in a different namespace
-------------------------------------

kubectl create -f <job.yaml>
creates a job that runs just once.
Job are preserved till the user removes them.

After the jobs complete, the pods associated with them are not visible anymore.
kubectl get pods --show-all 
displays the pods with status completed as well
-------------------------------------
kubectl logs <podName>
Displays the logs associated with the pod
-------------------------------------
kubectl create -f <cronjob.yaml>
creates a cronjob that runs periodically
-------------------------------------
kubectl get cronjobs
prints the cronjobs
-------------------------------------
daemonset: ensures that all nodes run a copy of a specific pod. As nodes get added, new pods get scehduled on it.
Can also use labelselectors 
-------------------------------------
statefulset: manages sticky identify of each pod along with ordering


Further reading:
https://github.com/kelseyhightower/kubernetes-the-hard-way - cloned locally already
