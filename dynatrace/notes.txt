Dynatrace

APM with proactive , reactive support.
synthetic monitoring - loading of pages - licensed
Real user monitoring - not used GDPR


Architecture:
DT Cluster: 3 nodes
WebUI & Control services - query from UI, Analytics services, cassandra NoSQL services, Nginx, Agent security services   -- each nodes

Cluster mgmt console -- only DT admins
Mission control monitoring -- Dynatrace folks can view the setup etc. Access can be revoked on request. Reactive support is still applicable, but not proactive support.


Agents use 8443 https to transmit data

Configurable:
purepaths - 10days   --- disk storage

Timeseries: CPU, memory, processtime, failure rate
1 min intervals -14 d
5min - 28 d+
1hr - 400 d
1 day - 5 yrs

Real user mgmt - Elasticsearch store : No. of user clicks etc.
sessions - 30d
Waterfall - 10d - first resource loaded on UI

Dynatrace clusters sent heartbeat messages to DT mission control . Updates are pushed to mission control, clusters pull the updates from MC.
heartbeat data - usage for billing, health stats, heardware utilization, CPU, events like updates, server restarts, removed nodes etc.

OneAgent updates are optional - 4 week updates - restart required! valid for one year
DT servers have audit logs to see user logins

Data retention - 35 days default - configurable

The oneAgent is also installed on the DT cluster itself, So that MC can view the health stats of the DT cluster.

Security Gateway: Sits in front of the DT cluster. all OneAgents connect to the SG to talk to DT cluster. No need to open firewall to multiple agents.
70% reduction in network traffic.

Agentless RUM requires SG to push data to the DT. Since there is no agent in the browser, the data cant be pushed to the DT server/cluster.

OneAgents are aware of all SGs. Firewall needs to be configured to ensure that the agent connects to desired SGs.

Licensing - criteria: 
full stack - depends on host memory 
Pass - only processtime
Infra only- only OS instance


OneAgent - package with multiple components to monitor multiple pieces of code like java, .net, js etc.
One piece to monitor CPU usage by multiple components
One piece for network - ports, package sampling
One piece for communication to dt custer
One piece for log monitoring - updated on demand only when they are accessed on the server, the oneAgent send them.  Logs analytics premium sends them actively and stored on the DT servers
One piece for disk

hot placement of the sensors. - instrumentation - wrappers on the methods
One Agent SDK for C, Ruby - the customer has to instrument it on their own.

Network monitoring component of oneAgent helps build the smartscape

Paas agents dont monitor network and disks


EasyTravel - properties to change: https://community.dynatrace.com/community/display/DL/Demo+Applications+-+easyTravel#DemoApplications-easyTravel-Advancedtopics

Definitions:
Host: anyting that is running a full stack Agent runs, Diego cell in SCP, pod in k8s, vm etc.
process: any process that shows up in task manager
Services: logical unit / endpoint that waits for methods to be called and returns a response
-----------------------------------------------------------------------------------------------------------------------------

Day 2:

Processes: Only important (deep injectable ones) are shown in the preview. More can be found in All processes of hosts view.
Process group: Group of processes that run the same code across hosts, Cannot change with deployment. Used to configure all of the processes at once.

DB full monitoring:
Settings > monitor technologies > configure DB type

Paas agents - the agent is defined in the buildpack to monitor the app deployed on CF.
Full stack - bosh addon will add the agent on CF which will in turn inject itself into all the containers. No buildpack integration required. to be installed as root.


Azure setup:
Setting up Paas agent on Azure: DT portal > Azure > follow the instructions. This will not inject itself into the vms

Setting up Dynatrace agent in the Azure vms: Generate a token for an environment on dynatrace, go to azure and this app setting of the webapp. and download and install dt extension. Good to go.
https://www.dynatrace.com/support/help/shortlink/azure
https://www.dynatrace.com/support/help/shortlink/azure-vm

Doesnt collect cpu level data as this is not a full stack agent.
These agents are disconnected and cannot see eachother.
A security gateway is required for Azure - dynatrace integration.


Tagging:
Values : optional - when setting it up on dt portal, a regex expression can be used after /.
example: Optional tag value: {ProcessGroup:CommandLineArgs/dynatrace-[*]}

Tags need to have a particular scope in the condition. There can be overtagging if both hosts and services are to be tagged according to your rule. 
If service 1 runs in both Host a and b, and the rule is to tag the service that run on hosts that contain name "manager", then only that should be selected. IF hosts options are also selected then both Host A and B will be tagged as the service exists in both A and B and the tag gets propgated to the other node even though it doesnt contain the name manager.

Tagging processGroups with Env variables would require app restart.

Custom added properties get fetched into the tag placeholders

Custom props need to be added before starting the app.Else restart app.

Host groups can only be configured during installation of oneAgent. Cannot be done later as it breaks the Process Groups.
Host groups can be changed only by redeploying the agent

Host CPU usage - fixed thresholds for CPU, memory, Availability
Processes - baselining for response time, failure rate, cpu/request

Service specific anamoly settings can be set.

For custom alerts, there will be no correlation (RCA for problem) provided by DT.
Management zones can be used to set filters for limiting the view to only certain criteria. Hybris uses it to separate Customer data. Customer filter seen on top.

-----------------------------------------------------------------------------------------------------------------------------

Day 3:
Process group detection: Regroup the existing pgs with a different criteria.
Custom process group detection: Some process groups dont get detected if the CPU consumption is less than 1%. Custom PG rules help in that case.

PG detection is at startup cannot change runtime. So, restart it.
Older data is still retained under old PG grouping.

Restricting the PG to a particular type will take upto a couple mins for DT to detect the  process type. So, the new naming maynot be visible immediately. So, better not use it.

Availability monitoring can be set up for process groups like 3 instances all the time. Hence, it is crucial to bucket the processes properly.
PG naming: Can also be done via Environment variables set on the VM.
DT_CLUSTER_ID: will be inherited by all of the Processes.
DT_NODE_ID: node level setting.

PG detection for Paas: Only via env variables
Full stack: rules + env variables

Custom service detection: Requires restart for instrumentation.
